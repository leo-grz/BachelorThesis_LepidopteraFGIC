{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from utils_helpers import check_folder_exists, load_features, save_features\n",
    "\n",
    "\n",
    "PATH_TO_DATA = '/home/lgierz/BA_MothClassification/data/'\n",
    "PATH_TO_CA = PATH_TO_DATA + 'confidance_analysis/'\n",
    "PATH_TO_DATASETS = PATH_TO_DATA + 'processed/cv_datasets/'\n",
    "PATH_TO_LOGFILE = PATH_TO_DATA + 'status/hyperparameter_tuning_dino_chunky_additionalOOPLRscheduler.log'\n",
    "feature_file = PATH_TO_DATA + 'processed/cv_datasets/dino_feature_dataset_top277_max1000.npz' \n",
    "csv_file_path = PATH_TO_DATA + 'status/hyperparameter_tuning_dino_chunky_additionalOOPLRscheduler.csv'\n",
    "\n",
    "model_names = [\"KNN\", \"Linear Classifier\"]\n",
    "fm_names = ['resnet', 'dino']\n",
    "\n",
    "\n",
    "config = {    \n",
    "    'pca__reduced_fe_size': 512,\n",
    "\n",
    "    'knn__neighbors': 60,\n",
    "\n",
    "    'linear__learning_rate': 0.001,\n",
    "    'linear__epochs': 1500,\n",
    "    'linear__patience': 3,\n",
    "    'linear__gamma': 0.8\n",
    "}\n",
    "\n",
    "dataset_configs = {\n",
    "    'top277': (277, [3000, 2000, 1000, 500]),\n",
    "    'top387': (387, [2000, 1000, 500]),\n",
    "    'top589': (589, [1000, 500])\n",
    "}\n",
    "\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     filename=PATH_TO_LOGFILE,\n",
    "#     level=logging.INFO,\n",
    "#     format='[%(asctime)s][%(levelname)s] - %(message)s',\n",
    "# )\n",
    "\n",
    "# console_handler = logging.StreamHandler() \n",
    "# console_handler.setLevel(logging.INFO) \n",
    "# console_handler.setFormatter(logging.Formatter('[%(asctime)s][%(levelname)s] - %(message)s')) \n",
    "# logger = logging.getLogger() \n",
    "# logger.addHandler(console_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top277_max3000.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 277, unique labels in testing ds: 277\n",
      "X_train shape: (664696, 2048), X_test shape: (166174, 2048), y_train shape: (664696,), y_test shape: (166174,), gbifids_train shape: (664696,), gbifids_test shape: (166174,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max3000_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max3000_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top277_max2000.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 277, unique labels in testing ds: 277\n",
      "X_train shape: (443200, 2048), X_test shape: (110800, 2048), y_train shape: (443200,), y_test shape: (110800,), gbifids_train shape: (443200,), gbifids_test shape: (110800,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max2000_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max2000_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top277_max1000.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 277, unique labels in testing ds: 277\n",
      "X_train shape: (221600, 2048), X_test shape: (55400, 2048), y_train shape: (221600,), y_test shape: (55400,), gbifids_train shape: (221600,), gbifids_test shape: (55400,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max1000_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max1000_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top277_max500.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 277, unique labels in testing ds: 277\n",
      "X_train shape: (110800, 2048), X_test shape: (27700, 2048), y_train shape: (110800,), y_test shape: (27700,), gbifids_train shape: (110800,), gbifids_test shape: (27700,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max500_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top277_max500_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top387_max2000.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 387, unique labels in testing ds: 387\n",
      "X_train shape: (619200, 2048), X_test shape: (154800, 2048), y_train shape: (619200,), y_test shape: (154800,), gbifids_train shape: (619200,), gbifids_test shape: (154800,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top387_max2000_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top387_max2000_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top387_max1000.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 387, unique labels in testing ds: 387\n",
      "X_train shape: (309600, 2048), X_test shape: (77400, 2048), y_train shape: (309600,), y_test shape: (77400,), gbifids_train shape: (309600,), gbifids_test shape: (77400,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top387_max1000_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top387_max1000_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top387_max500.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 387, unique labels in testing ds: 387\n",
      "X_train shape: (154800, 2048), X_test shape: (38700, 2048), y_train shape: (154800,), y_test shape: (38700,), gbifids_train shape: (154800,), gbifids_test shape: (38700,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top387_max500_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top387_max500_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top589_max1000.npz\n",
      "Lowest label: 0, highest label: 588, unique labels in training ds: 589, unique labels in testing ds: 589\n",
      "X_train shape: (471199, 2048), X_test shape: (117800, 2048), y_train shape: (471199,), y_test shape: (117800,), gbifids_train shape: (471199,), gbifids_test shape: (117800,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top589_max1000_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top589_max1000_test.npz\n",
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/resnet_feature_dataset_top589_max500.npz\n",
      "Lowest label: 0, highest label: 588, unique labels in training ds: 589, unique labels in testing ds: 589\n",
      "X_train shape: (235600, 2048), X_test shape: (58900, 2048), y_train shape: (235600,), y_test shape: (58900,), gbifids_train shape: (235600,), gbifids_test shape: (58900,)\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top589_max500_train.npz\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/confidance_analysis/split_datasets/resnet_feature_dataset_top589_max500_test.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fm in fm_names:\n",
    "\n",
    "    # Iterate through dataset configurations\n",
    "    for dataset_name, (class_amount, sample_amounts) in dataset_configs.items():\n",
    "        \n",
    "        # Iterate through the sample amounts\n",
    "        for sample_amount in sample_amounts:\n",
    "\n",
    "            feature_file = PATH_TO_DATASETS + f'{fm}_feature_dataset_top{class_amount}_max{sample_amount}.npz'\n",
    "\n",
    "            features, labels, gbifids = load_features(feature_file)\n",
    "\n",
    "            X_train, X_test, y_train, y_test, gbifids_train, gbifids_test = train_test_split(features, labels, gbifids, test_size=0.2, random_state=42, stratify=labels)\n",
    "            print(f'Lowest label: {np.min(y_train)}, highest label: {np.max(y_train)}, unique labels in training ds: {len(np.unique(y_train))}, unique labels in testing ds: {len(np.unique(y_test))}')\n",
    "            print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}, y_train shape: {y_train.shape}, y_test shape: {y_test.shape}, gbifids_train shape: {gbifids_train.shape}, gbifids_test shape: {gbifids_test.shape}')\n",
    "            save_features(X_train, y_train, gbifids_train, PATH_TO_CA + 'split_datasets/' + f'{fm}_feature_dataset_top{class_amount}_max{sample_amount}_train.npz')\n",
    "            save_features(X_test, y_test, gbifids_test, PATH_TO_CA + 'split_datasets/' + f'{fm}_feature_dataset_top{class_amount}_max{sample_amount}_test.npz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features, labels, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_features\u001b[49m(feature_file)\n\u001b[1;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(features, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLowest label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmin(y_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, highest label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmax(y_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, unique labels in training ds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, unique labels in testing ds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_test))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# fix missing labels due to dataset splitting by changing label to ascending order\n",
    "label_mapping = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "y_train = np.array([label_mapping[label] for label in y_train]) # since labels are not in ascending order, remapping is necessary\n",
    "y_test = np.array([label_mapping[label] for label in y_test])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes): \n",
    "        super(LinearClassifier, self).__init__() \n",
    "        self.fc = nn.Linear(input_dim, num_classes) \n",
    "        \n",
    "    def forward(self, x): \n",
    "        \treturn self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "reducer = PCA(n_components=config['pca__reduced_fe_size'])\n",
    "\n",
    "start_time = time.time()\n",
    "X_train_reduced = reducer.fit_transform(X_train)\n",
    "X_test_reduced = reducer.transform(X_test) if hasattr(reducer, 'transform') else reducer.fit_transform(X_test)\n",
    "reduction_time = time.time() - start_time\n",
    "\n",
    "print(f'SHAPES: normal train: {X_train.shape} | reduced train: {X_train_reduced.shape}')\n",
    "print(f'SHAPES: normal test: {X_test.shape} | reduced test: {X_test_reduced.shape}')\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    if model_name == \"Linear Classifier\":\n",
    "        \n",
    "        losses, accuracies = [], []\n",
    "        # PyTorch Model Setup\n",
    "        input_dim = X_train_reduced.shape[1]\n",
    "        num_classes = 277 # TODO: Change\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        linear_model = LinearClassifier(input_dim, num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(linear_model.parameters(), lr=config['linear__learning_rate'])\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=config['linear__gamma'], patience=config['linear__patience'], min_lr=0.0001)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_reduced, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)  # Convert to Long type for CrossEntropyLoss\n",
    "\n",
    "        for epoch in range(config['linear__epochs']):\n",
    "            linear_model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = linear_model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "\n",
    "            # calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the predicted class indices\n",
    "            correct = (predicted == y_train_tensor).sum().item()  # Count correct predictions\n",
    "            accuracy = correct / y_train_tensor.size(0)  # Calculate accuracy\n",
    "\n",
    "            losses.append(round(loss.item(), 4))\n",
    "            accuracies.append(round(accuracy, 4))\n",
    "\n",
    "        # Evaluate Linear Classifier\n",
    "        linear_model.eval()\n",
    "        X_test_tensor = torch.tensor(X_test_reduced, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)  # Convert to Long type for evaluation\n",
    "        with torch.no_grad():\n",
    "            outputs = linear_model(X_test_tensor)\n",
    "            _, y_pred = torch.max(outputs, 1)  # Get the predicted class indices\n",
    "            y_pred_numpy = y_pred.cpu().numpy()\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Save the linear model\n",
    "        with open(PATH_TO_DATA + 'linear_model.pkl', 'wb') as f:\n",
    "            pickle.dump(linear_model, f)\n",
    "\n",
    "    elif model_name == 'KNN':\n",
    "        start_time = time.time()\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=config['knn__neighbors'])\n",
    "        model.fit(X_train_reduced, y_train)\n",
    "        y_pred_numpy = model.predict(X_test_reduced)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Save the KNN model\n",
    "        with open(PATH_TO_DATA + 'knn_model.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    else:\n",
    "        print(f'INVALID MODEL NAME: {model_name}')\n",
    "        sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidance tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement:\n",
    "- Class lookup using gbifid\n",
    "- Extraction of Models for each Dataset\n",
    "- Save confidances during training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
