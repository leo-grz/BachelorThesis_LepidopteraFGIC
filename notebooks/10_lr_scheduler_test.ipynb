{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from lepidoptera_dataset import LepidopteraDataset, get_labelencoding\n",
    "from utils_helpers import show_sample, check_folder_exists, save_features, load_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_DATA = '/home/lgierz/BA_MothClassification/data/'\n",
    "PATH_TO_LOGFILE = PATH_TO_DATA + 'status/hyperparameter_tuning_resnet_chunky_32to1024a100fix.log'\n",
    "feature_file = PATH_TO_DATA + 'processed/cv_datasets/dino_feature_dataset_top277_max3000.npz' \n",
    "csv_file_path = PATH_TO_DATA + 'status/hyperparameter_tuning_resnet_chunky_32to1024a100fix.csv'\n",
    "\n",
    "model_names = [\"Linear Classifier\"]\n",
    "\n",
    "config = {\n",
    "    # 'linear__learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "    # 'linear__epochs': [250,500,750,1000,1500],\n",
    "\n",
    "    'linear__learning_rate': [0.001],\n",
    "    'linear__epochs': [1500],\n",
    "    'linear__patience': [3,5,10],\n",
    "    'linear__gamma': [0.2, 0.5, 0.8, 0.95]\n",
    "}\n",
    "\n",
    "DATASET_CONFIGS = {\n",
    "    'top277': (277, [500, 1000, 2000,3000]),\n",
    "    'top387': (387, [500, 1000, 2000]),\n",
    "    'top589': (589, [500,1000])\n",
    "}\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=PATH_TO_LOGFILE,\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(levelname)s] - %(message)s',\n",
    ")\n",
    "\n",
    "console_handler = logging.StreamHandler() \n",
    "console_handler.setLevel(logging.INFO) \n",
    "console_handler.setFormatter(logging.Formatter('[%(asctime)s][%(levelname)s] - %(message)s')) \n",
    "logger = logging.getLogger() \n",
    "logger.addHandler(console_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/cv_datasets/dino_feature_dataset_top277_max3000.npz\n",
      "Lowest label: 2, highest label: 588, unique labels in training ds: 277, unique labels in testing ds: 277\n"
     ]
    }
   ],
   "source": [
    "features, labels, _ = load_features(feature_file)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "\n",
    "print(f'Lowest label: {np.min(y_train)}, highest label: {np.max(y_train)}, unique labels in training ds: {len(np.unique(y_train))}, unique labels in testing ds: {len(np.unique(y_test))}')\n",
    "\n",
    "# fix missing labels due to dataset splitting by changing label to ascending order\n",
    "label_mapping = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "y_train = np.array([label_mapping[label] for label in y_train]) # since labels are not in ascending order, remapping is necessary\n",
    "y_val = np.array([label_mapping[label] for label in y_val])\n",
    "y_test = np.array([label_mapping[label] for label in y_test])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def handle_results(csv_path, test, pred, method, model, params, reduction_time, training_time, neighbors=None, C=None, lr=None, epochs=None, val_losses=None, val_accuracies=None, gamma=None, patience=None):\n",
    "    acc = accuracy_score(test, pred)\n",
    "    prec = precision_score(test, pred, average='weighted')\n",
    "    rec = recall_score(test, pred, average='weighted')\n",
    "    f1 = f1_score(test, pred, average='weighted')\n",
    "\n",
    "    # Store Results\n",
    "    run_results = {\n",
    "        \"Method\": method,\n",
    "        \"Model\": model,\n",
    "        \"Parameters\": params,\n",
    "        \"Reduction Time (s)\": round(reduction_time, 2),\n",
    "        \"Training Time (s)\": round(training_time, 2),\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision\": round(prec, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"F1-Score\": round(f1, 4),\n",
    "        \"Neighbors\": neighbors if model == 'KNN' else None,\n",
    "        \"C\": C if model == 'SVM' else None,\n",
    "        \"Learning Rate\": lr if model == \"Linear Classifier\" else None,\n",
    "        \"Epochs\": epochs if model == \"Linear Classifier\" else None,\n",
    "        \"Gamma\": gamma if model == \"Linear Classifier\" else None,\n",
    "        \"Patience\": patience if model == \"Linear Classifier\" else None,\n",
    "        \"Validation Accuracies\": val_accuracies if model == \"Linear Classifier\" else None,\n",
    "        \"Validation Losses\": val_losses if model == \"Linear Classifier\" else None\n",
    "    }\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    results_df = pd.DataFrame([run_results])  # Wrap in a list to create a DataFrame with one row\n",
    "    # if not os.path.isfile(csv_path):\n",
    "    #     results_df.to_csv(csv_path, index=False)\n",
    "    # else:\n",
    "    #     results_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "    logging.info(f\"[{run_results['Method']} ({run_results['Parameters']})][{run_results['Model']}] Reduction time: {run_results['Reduction Time (s)']}s, Training time: {run_results['Training Time (s)']}s, Accuracy: {run_results['Accuracy']}, Precision: {run_results['Precision']}, Recall: {run_results['Recall']}, F1-Score: {run_results['F1-Score']}\")\n",
    "\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes): \n",
    "        super(LinearClassifier, self).__init__() \n",
    "        self.fc = nn.Linear(input_dim, num_classes) \n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.fc(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPES: normal train: (664696, 1536) | reduced train: (664696, 1024)\n",
      "SHAPES: normal val: (83087, 1536) | reduced val: (83087, 1024)\n",
      "SHAPES: normal test: (83087, 1536) | reduced test: (83087, 1024)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reducer = PCA(n_components=1024, random_state=42)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "X_train_reduced = reducer.fit_transform(X_train)\n",
    "X_val_reduced = reducer.transform(X_val) if hasattr(reducer, 'transform') else reducer.fit_transform(X_val)\n",
    "X_test_reduced = reducer.transform(X_test) if hasattr(reducer, 'transform') else reducer.fit_transform(X_test)\n",
    "reduction_time = time.time() - start_time\n",
    "\n",
    "print(f'SHAPES: normal train: {X_train.shape} | reduced train: {X_train_reduced.shape}')\n",
    "print(f'SHAPES: normal val: {X_val.shape} | reduced val: {X_val_reduced.shape}')\n",
    "print(f'SHAPES: normal test: {X_test.shape} | reduced test: {X_test_reduced.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Classifier with PCA feature embeddings [LR: 0.001 | Epochs: 1500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-16 19:05:30,499][INFO] - [PCA (512 components)][Linear Classifier] Reduction time: 161.08s, Training time: 0.77s, Accuracy: 0.003, Precision: 0.0034, Recall: 0.003, F1-Score: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7701408863067627\n"
     ]
    }
   ],
   "source": [
    "for epochs in config['linear__epochs']:\n",
    "    for lr in config['linear__learning_rate']:\n",
    "\n",
    "        print(f\"Training Linear Classifier with PCA feature embeddings [LR: {lr} | Epochs: {epochs}]\")\n",
    "        val_accuracies, val_losses = [], []\n",
    "        # PyTorch Model Setup\n",
    "        input_dim = X_train_reduced.shape[1]\n",
    "        num_classes = 277\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        linear_model = LinearClassifier(input_dim, num_classes).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(linear_model.parameters(), lr=lr)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, \n",
    "                        mode='min',\n",
    "                        factor=0.9, \n",
    "                        threshold=0.01,\n",
    "                        patience=3,\n",
    "                        min_lr=1e-6)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_reduced, dtype=torch.float32).to(device)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "        X_val_tensor = torch.tensor(X_val_reduced, dtype=torch.float32).to(device)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        best_model = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            linear_model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            outputs = linear_model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Validation accuracy and loss\n",
    "            linear_model.eval()\n",
    "            with torch.no_grad():\n",
    "\n",
    "                val_outputs = linear_model(X_val_tensor)\n",
    "                val_loss = criterion(val_outputs, y_val_tensor)\n",
    "                scheduler.step(val_loss)\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_correct = (val_predicted == y_val_tensor).sum().item()\n",
    "                val_accuracy = val_correct / y_val_tensor.size(0)\n",
    "                val_losses.append(round(val_loss.item(), 4))\n",
    "                val_accuracies.append(round(val_accuracy, 4))\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{epochs}] - Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}, Current LR: {scheduler.optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        # Evaluate Linear Classifier\n",
    "        linear_model.eval()\n",
    "        X_test_tensor = torch.tensor(X_test_reduced, dtype=torch.float32).to(device)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)  # Convert to Long type for evaluation\n",
    "        with torch.no_grad():\n",
    "            outputs = linear_model(X_test_tensor)\n",
    "            _, y_pred = torch.max(outputs, 1)  # Get the predicted class indices\n",
    "            y_pred_numpy = y_pred.cpu().numpy()\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        print(training_time)\n",
    "\n",
    "        handle_results(csv_file_path, y_test, y_pred_numpy, 'PCA', 'Linear Classifier', \n",
    "                   '512 components', reduction_time, training_time, neighbors=None,\n",
    "                    lr=lr, epochs=epochs, val_accuracies=val_accuracies, val_losses=val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
