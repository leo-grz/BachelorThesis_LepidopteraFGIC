{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from lepidoptera_dataset import LepidopteraDataset\n",
    "from utils import show_sample, check_folder_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device chosen: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configuration of Cross Validation and logging\n",
    "\n",
    "PATH_TO_DATA = '/home/lgierz/BA_MothClassification/data/'\n",
    "PATH_TO_DATASETS = PATH_TO_DATA + 'processed/cv_datasets/'\n",
    "PATH_TO_IMAGES = '/mnt/data/lgierz/moth_dataset_top589_max3000/'\n",
    "PATH_TO_FEATURES = PATH_TO_DATA + 'processed/features/'\n",
    "PATH_TO_LOGFILE = PATH_TO_DATA + 'status/feature_extraction.log'\n",
    "\n",
    "for folder in [PATH_TO_DATA, PATH_TO_DATASETS, PATH_TO_IMAGES, PATH_TO_FEATURES]:\n",
    "    check_folder_exists(folder, min_fileamount=0)\n",
    "\n",
    "FOLDS = 10\n",
    "\n",
    "KNN_PARAM_GRID = {\n",
    "    'n_neighbors': [5,10,15,20,30],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree'],#, 'kd_tree', 'brute'],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "SCORER = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "FOUNDATIONAL_MODELS = [\n",
    "    'ResNet50_ImageNet1KV1', \n",
    "    'ResNet50_ImageNet1KV2', \n",
    "    'ResNet101_ImageNet1KV1', \n",
    "    'ResNet101_ImageNet1KV1'\n",
    "]\n",
    "\n",
    "DATASETS = {\n",
    "    'top277_max3000': PATH_TO_DATASETS + 'dataset_top277_max3000.csv',\n",
    "    'top277_max2000': PATH_TO_DATASETS + 'dataset_top277_max2000.csv',\n",
    "    'top277_max1000': PATH_TO_DATASETS + 'dataset_top277_max1000.csv',\n",
    "    'top277_max500': PATH_TO_DATASETS + 'dataset_top277_max500.csv',\n",
    "\n",
    "    'top387_max2000': PATH_TO_DATASETS + 'dataset_top387_max2000.csv',\n",
    "    'top387_max1000': PATH_TO_DATASETS + 'dataset_top387_max1000.csv',\n",
    "    'top387_max500': PATH_TO_DATASETS + 'dataset_top387_max500.csv',\n",
    "\n",
    "    'top589_max1000': PATH_TO_DATASETS + 'dataset_top589_max1000.csv',\n",
    "    'top589_max500': PATH_TO_DATASETS + 'dataset_top589_max500.csv'\n",
    "}\n",
    "\n",
    "DATASET_NAME = 'top277_max3000'\n",
    "MODEL_NAME = FOUNDATIONAL_MODELS[1]\n",
    "\n",
    "PATH_TO_LABELS = DATASETS[DATASET_NAME]\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=PATH_TO_LOGFILE,\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s][%(levelname)s] - %(message)s',\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device chosen: {device}')\n",
    "logging.info(f'[INIT] Device chosen: {device}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATASET] In-memory index built.\n",
      "Dataset contains 830870 samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# LOADING DATASET\n",
    "\n",
    "# prepare rows not containing BLACK / CHECK to be inspected by brightness check and objective size estimation\n",
    "csv_file = pd.read_csv(PATH_TO_LABELS)\n",
    "csv_file['status'] = csv_file['status'].astype('str') # to ensure status (CHECK, WHITE, BLACK) is of type string\n",
    "\n",
    "ignore_statuses = ['CHECK', 'BLACK', 'MISSING'] # these statuses are ignored in dataset\n",
    "csv_file_filtered = csv_file[~csv_file['status'].isin(ignore_statuses)] # selects all samples which's status has not been set to CHECK or BLACK\n",
    "csv_file_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match ResNet input size\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "])\n",
    "\n",
    "full_dataset = LepidopteraDataset(csv_file=csv_file_filtered, root_dir=PATH_TO_IMAGES, transform=transform)\n",
    "\n",
    "\n",
    "print(f'Dataset contains {len(full_dataset)} samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "\n",
    "    if model_name == 'DINOv2basic': \n",
    "        model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "        model.head = nn.Identity()\n",
    "    elif model_name == 'DINOv2large': \n",
    "        model = models.vit_l_16(weights=models.ViT_L_16_Weights.DEFAULT)\n",
    "        model.head = nn.Identity()   \n",
    "\n",
    "    # different resnets\n",
    "    elif model_name == 'ResNet50_ImageNet1KV1':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Identity()\n",
    "    elif model_name == 'ResNet50_ImageNet1KV2':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        model.fc = nn.Identity()\n",
    "    elif model_name == 'ResNet101_ImageNet1KV1':\n",
    "        model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1)\n",
    "        model.fc = nn.Identity() #\n",
    "    elif model_name == 'ResNet101_ImageNet1KV2':\n",
    "        model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2)\n",
    "        model.fc = nn.Identity()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model name\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def extract_features_resnet(loader, model_name):\n",
    "    print('Called Feature Extraction Function')\n",
    "    model = get_model(model_name)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        print('Starting feature extraction process...')\n",
    "        for batch, (images, lbls, gbifids, _ ) in enumerate(loader, start=1):\n",
    "            logging.info(f'[FEATURE EXTRACTION] Batch [{batch+1}/{len(loader)}] with {len(images)} samples')\n",
    "            if (batch + 1) % 2 == 0: print(f'Batch [{batch+1}/{len(loader)}] with {len(images)} samples') \n",
    "            valid_indices = []\n",
    "\n",
    "            for idx, lbl in enumerate(lbls): # sorting out images that could not be read\n",
    "                if int(lbl) >= 0: # valid label if 0 or above, if negative, there has been an error with the sample\n",
    "                    valid_indices.append(idx)\n",
    "                else:\n",
    "                    logging.error(f'[FEATURE EXTRACTION] Image with gbifID {gbifids[idx]} couldn\\'t be read.')\n",
    "                    print(f'[FEATURE EXTRACTION] Image with gbifID {gbifids[idx]} couldn\\'t be read.')\n",
    "\n",
    "            images = images[valid_indices]\n",
    "            lbls = lbls[valid_indices]\n",
    "\n",
    "            images = images.to(device)\n",
    "            lbls = lbls.to(device)\n",
    "            \n",
    "            outputs = model(images).cpu().numpy()\n",
    "            features.append(outputs)\n",
    "            labels.append(lbls.cpu().numpy())\n",
    "            if batch % 50 == 0:\n",
    "                gc.collect() \n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    features = np.concatenate(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    return features, labels\n",
    "\n",
    "def save_features(features, labels, filename): \n",
    "    np.savez_compressed(filename, features=features, labels=labels) \n",
    "    print(f\"Features and labels saved to {filename}\") \n",
    "    \n",
    "def load_features(filename): \n",
    "    data = np.load(filename) \n",
    "    features = data['features'] \n",
    "    labels = data['labels'] \n",
    "    print(f\"Features and labels loaded from {filename}\") \n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet50_ImageNet1KV2\n",
      "Dataset: top277_max3000\n",
      "Called Feature Extraction Function\n",
      "Starting feature extraction process...\n",
      "[DATASET][ERROR] cannot identify image file '/mnt/data/lgierz/moth_dataset_top589_max3000/4887899402_89095802.jpg'\n",
      "[DATASET][ERROR] cannot identify image file '/mnt/data/lgierz/moth_dataset_top589_max3000/4889518310_90140725.jpg'Batch [2/84] with 1000 samples\n",
      "\n",
      "Batch [4/84] with 1000 samples\n",
      "Batch [6/84] with 1000 samples\n",
      "Batch [8/84] with 1000 samples\n",
      "Batch [10/84] with 1000 samples\n",
      "Batch [12/84] with 1000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [14/84] with 1000 samples\n",
      "Batch [16/84] with 1000 samples\n",
      "Batch [18/84] with 1000 samples\n",
      "Batch [20/84] with 1000 samples\n",
      "Batch [22/84] with 1000 samples\n",
      "[FEATURE EXTRACTION] Image with gbifID 4887899402 couldn't be read.\n",
      "[DATASET][ERROR] cannot identify image file '/mnt/data/lgierz/moth_dataset_top589_max3000/3730297094_35249935.jpg'\n",
      "Batch [24/84] with 1000 samples\n",
      "Batch [26/84] with 1000 samples\n",
      "Batch [28/84] with 1000 samples\n",
      "Batch [30/84] with 1000 samples\n",
      "Batch [32/84] with 1000 samples\n",
      "Batch [34/84] with 1000 samples\n",
      "Batch [36/84] with 1000 samples\n",
      "Batch [38/84] with 1000 samples\n",
      "Batch [40/84] with 1000 samples\n",
      "Batch [42/84] with 1000 samples\n",
      "Batch [44/84] with 1000 samples\n",
      "Batch [46/84] with 1000 samples\n",
      "Batch [48/84] with 1000 samples\n",
      "[FEATURE EXTRACTION] Image with gbifID 4889518310 couldn't be read.\n",
      "Batch [50/84] with 1000 samples\n",
      "Batch [52/84] with 1000 samples\n",
      "Batch [54/84] with 1000 samples\n",
      "Batch [56/84] with 1000 samples\n",
      "Batch [58/84] with 1000 samples\n",
      "Batch [60/84] with 1000 samples\n",
      "Batch [62/84] with 1000 samples\n",
      "Batch [64/84] with 1000 samples\n",
      "Batch [66/84] with 1000 samples\n",
      "Batch [68/84] with 1000 samples\n",
      "[FEATURE EXTRACTION] Image with gbifID 3730297094 couldn't be read.\n",
      "Batch [70/84] with 1000 samples\n",
      "Batch [72/84] with 1000 samples\n",
      "Batch [74/84] with 1000 samples\n",
      "Batch [76/84] with 1000 samples\n",
      "Batch [78/84] with 1000 samples\n",
      "Batch [80/84] with 1000 samples\n",
      "Batch [82/84] with 1000 samples\n",
      "Batch [84/84] with 1000 samples\n",
      "Features and labels saved to /home/lgierz/BA_MothClassification/data/processed/features/test_features_ResNet50_ImageNet1KV2_top277_max3000.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_train_val_indices, test_indices = train_test_split(range(len(full_dataset)), test_size=0.1, shuffle=True, random_state=42) # no stratification required, no class imbalance\n",
    "cv_train_val_dataset = torch.utils.data.Subset(full_dataset, cv_train_val_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_dataset, test_indices)\n",
    "\n",
    "cv_train_val_loader = DataLoader(cv_train_val_dataset, batch_size=1000, shuffle=False, num_workers=24, prefetch_factor=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=24, prefetch_factor=2, pin_memory=True)\n",
    "\n",
    "#full_loader = DataLoader(full_dataset, batch_size=1000, shuffle=False, num_workers=24, prefetch_factor=2, pin_memory=True)\n",
    "\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Dataset: {DATASET_NAME}')\n",
    "#Extract features for training and validation sets\n",
    "cv_train_val_features, cv_train_val_labels = extract_features_resnet(cv_train_val_loader, MODEL_NAME)\n",
    "PATH_TO_FEATURES_CV_TRAIN_VAL = PATH_TO_FEATURES + f'cv_train_val_features_{MODEL_NAME}_{DATASET_NAME}.npz'\n",
    "save_features(cv_train_val_features, cv_train_val_labels, PATH_TO_FEATURES_CV_TRAIN_VAL)\n",
    "\n",
    "test_features, test_labels = extract_features_resnet(test_loader, MODEL_NAME)\n",
    "PATH_TO_FEATURES_TEST = PATH_TO_FEATURES + f'test_features_{MODEL_NAME}_{DATASET_NAME}.npz'\n",
    "save_features(test_features, test_labels, PATH_TO_FEATURES_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels loaded from /home/lgierz/BA_MothClassification/data/processed/features/cv_train_val_features_ResNet50_ImageNet1KV2_top277_max3000.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_FEATURES_CV_TRAIN_VAL = PATH_TO_FEATURES + f'cv_train_val_features_{MODEL_NAME}_{DATASET_NAME}.npz'\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "# knn = KNeighborsClassifier()\n",
    "# grid_search = GridSearchCV(estimator=knn, param_grid=KNN_PARAM_GRID, scoring='accuracy', cv=skf, verbose=2, n_jobs=24)\n",
    "loaded_features, loaded_labels = load_features(PATH_TO_FEATURES_CV_TRAIN_VAL)\n",
    "# grid_search.fit(loaded_features, loaded_labels)\n",
    "loaded_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746787"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = loaded_features[0]\n",
    "\n",
    "feature_set = set(map(tuple, loaded_features))\n",
    "len(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_labels[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mydf = {'feature': loaded_features.tolist(),\n",
    "        'label': list(loaded_labels)}\n",
    "\n",
    "df = pd.DataFrame(mydf)\n",
    "df['feature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Cross Validation performed with {len(cv_train_val_features)} features and {len(cv_train_val_labels)} labels.')\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {best_score:.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate the KNN classifier on the validation set using the best estimator found by GridSearchCV\n",
    "\n",
    "print(f'Final test on best parameters performed with {len(test_features)} features and {len(test_labels)} labels.')\n",
    "loaded_features, loaded_labels = load_features(PATH_TO_FEATURES_TEST)\n",
    "\n",
    "test_predictions = grid_search.best_estimator_.predict(loaded_features)\n",
    "accuracy = accuracy_score(loaded_labels, test_predictions)\n",
    "print(f\"Testing Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# save results of runs in processed/results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- implement extensive logging and data gathering for later visualization\n",
    "- separate PARAMS für Linear o.ä.? -> epochs\n",
    "- wie kann ich results in csv katalogisieren/kategorisieren\n",
    "- direkt Ergebnisse anschaulich darstellen?\n",
    "- einzelne zellenergebnisse zwischenspeichern wenn auf workstation in einem script executed?\n",
    "- andere datensätze erstellen\n",
    "- DINOv2 Implementieren\n",
    "- welche andere Optionen gibt es noch anstatt von DINO2 oder ResNet?\n",
    "- welche params kommen für KNN CV in frage und warum?\n",
    "- umap\n",
    "- gewichtung ähnliche klassen nur bei linear?\n",
    "\n",
    "### Todo Todday:\n",
    "- create dataset resized for experiment\n",
    "- dataset status updates (MISSING)\n",
    "- dataset sort out dark samples (BLACK)\n",
    "\n",
    "- send to device (GPU on Workstation)\n",
    "- implement logging\n",
    "- welche Versionen von ResNet und DINOv2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
